## 请查阅文献资料梳理Web（World Wide Web）的发展历史。

### World Wide Web
万维网，通常指的是网页和网站，现在已经是互联网的代名词，也是互联网中重要的核心部分。到目前为止，web发展已经有将近30年的历史了，万维网也经历了web1.0到web3.0的发展。从最初的商业用途到现在的人人皆用，人类时代已经到了互联网时代。

蒂姆·伯纳斯·李（Tim Berners-Lee）英国计算机科学家。
他是万维网的发明者，南安普顿大学与麻省理工学院教授。1990年12月25日，罗伯特·卡里奥在CERN和他一起成功通过Internet实现了HTTP代理与服务器的第一次通讯。
万维网联盟（W3C）是伯纳斯·李为关注万维网发展而创办的组织，并担任万维网联盟的主席。他也是万维网基金会的创办人。伯纳斯-李还是麻省理工学院计算机科学及人工智能实验室创办主席及高级研究员。同时，伯纳斯-李是网页科学研究倡议会的总监。最后，他是麻省理工学院集体智能中心咨询委员会成员。

### 第一个网站
蒂姆·伯纳斯－李建立的第一个网站（也是世界上第一个网站）是http: //info. cern. ch/，它于1991年8月6日上网，它解释了万维网是什么，如何使用网页浏览器和如何建立一个网页服务器等等。蒂姆·伯纳斯－李后来在这个网站里列举了其它网站，因此它也是世界上第一个万维网目录。

### 万维网标准
1994年伯纳斯－李在麻省理工学院创立了万维网联盟，它由不同的原意建立万维网标准和提高万维网质量的公司组成。 2004年12月接受了南安普敦大学计算机学院的教授职位，他在那里研究语义网。

### 免版权费
构成万维网的各个组成部分都很简单，伯纳斯－李的功绩是将它们有效地组合在一起使它们发挥出最大的效用。他最大的贡献可能是无偿地将他的主意提供出来而不收费。2003年万维网联盟决定所有由联盟提出的技术都是无偿的，所有人都可以简单地使用。

布兰登·艾克
1995年五月，Eich花了大约一周的时间完成了脚本语言的设计。
1995年九月，Netscape2.0测试版发布，命名为LiveScript。
1995年12月，NetScape2.0 beta3中改名为JavaScript。

### HTML
超文本标记语言，标准通用标记语言下的一个应用。是 网页制作必备的编程语言
“超文本”就是指页面内可以包含图片、链接，甚至音乐、程序等非文字元素。
超文本标记语言的结构包括“头”部分（英语：Head）、和“主体”部分（英语：Body），其中“头”部提供关于网页的信息，“主体”部分提供网页的具体内容。

### 层叠样式表
CSS （层叠样式表）
层叠样式表(英文全称：Cascading Style Sheets)是一种用来表现HTML（标准通用标记语言的一个应用）或XML（标准通用标记语言的一个子集）等文件样式的计算机语言。CSS不仅可以静态地修饰网页，还可以配合各种脚本语言动态地对网页各元素进行格式化。 [1]
CSS 能够对网页中元素位置的排版进行像素级精确控制，支持几乎所有的字体字号样式，拥有对网页对象和模型样式编辑的能力。

1994年 Hakon Wium Lie 提出，Bert Bos 共同参与设计。
1996年W3C正式发布第一版CSS1.0。
1996年IE3第一个部分支持。
2000年 IE5 for mac 第一个彻底支持CSS1.0。

### 前端工程师
2000年左右，雅虎等公司开始设立前端工程师职位。

2005年 Ajax 应用于Gmail ，Goole Maps。
2009年，百度、阿里、腾讯设立前端工程师职位。


## 请简要分析WEB1.0、WEB2.0和WEB3.0的区别,简要说明各自的特点。

### Web1.0的发展
Web1.0是万维网发展的第一代模式，Brian (2007)指出：“根据Berners-Lee，web1.0是只读模式的网络”。Web1.0一开始是为大型企业、商业公司服务，将企业的信息搬运到网上，向人们宣传企业。Web1.0是静态的、单项的网络。大型商业公司通过网络把他们的产品发布到网上，然后人们可以通过网络浏览信息，如果客户有中意的商品，便可以和公司取得联系。此外，第一代web用途相当有限，只是简单的信息检索。
19世纪中期（1996年）HTML的出现推动了家用计算机的普及以技术创新为主导，注重点击浏览，通过门户整合，用户以流量为主，以网页制作为主，大多是静态页面，也有动态页面


Web1.0的主要协议是HTTP, HTML and URI。

Web 1.0只解决了人对信息搜索、聚合的需求，而没有解决人与人之间沟通、互动和参与的需求。”因此，为了满足广大网民的需求，对于二代网络的开发已迫在眉睫。

### ### Web 2.0
1990年，伯纳斯李发布构架万维网（WWW）的三大基本技术，互联网自此进入了Web时代。由于web的内容让网民耳目一新，它结合音频、视频、图像，运用多媒体模式，给网民带来了一种空前的视觉享受，因此，自从面世以来，很快引起了人们的广泛关注，发展异常迅猛。到了1997年全球互联网数量已达到100万个，2000年更突破1000万。Web2.0是相对于web1.0 提出的一个新概念，是2003/4年的热词。

大约在2004年左右，诞生了WEB2.0的概念，更注重用户的交互作用，用户既是浏览者，也是内容的制造者，在模式上有单纯的“读”向“写”以及共同建设发展。


较之1.0，2.0web 的最大改变是，web2.0不再是单维的，逐渐发展为双向交流，另一特征是社交网络的兴起。Web1.0主要依赖于html语言，最大的缺陷是交互性差，用户每提交一次数据，都要停下来等待互联网的响应，在网站出现响应之前，用户至能看到一个空白网页无所事事，这一缺陷在web2.0上市后得以很好的解决。

### Web 3.0
WEB3.0是一个正在尝试概念，用户拥有自己的数据，并能在不同平台交互共享，强化虚拟货币及网络安全和网络财富的共识，以及语义化的实现


Web3.0实现了网络高度虚拟化，给予网民更大的自由空间，更能体现网民的自我需求，体现了高度的个性化，互动性，和更加深入全面的软件应用。Web 3.0为读者提供了更多的阅读渠道，内容也比之前的Web1.0 和2.0丰富。

Web 3.0为读者提供了更多的阅读渠道，内容也比之前的Web1.0 和2.0丰富。Web 3.0实现了网络融化的大众化，公用显示器与个人应用终端的通用。


因此，可以说web3.0是一个更具个性化特点的网络，它为用户提供个性化用户体验、个性化配置。另一方面，Web 3.0处处为用户着想，将用户的喜好作为软件开发的主要动因。在网络搜索方面，Web 3.0引入个人信息偏好处理系统和个性化搜索引擎，对个体用户进行特征分析，同时也对整个互联网的搜索习惯进行整理，归类，最终得出更适合网民需求的搜索平台，实现了快捷、准确、高效的搜索，用户可以可以在极短时间内找到自己需要的信息资料，节省了时间和精力。

这种个性化引擎的建立，是以网民偏好为基础，为了满足特定用户的需求，这就需求信息的大聚合，大量的个性化信息的聚合，造就了新的搜索引擎的面世。


## 结合近来的新冠疫情，请查阅资料用真实案例说明大数据分析（数据挖掘）、人工智能助力抗疫的主要应用，并结合所学专业知识谈谈你的初步认识和体会。
1. 有力支持疫情防控知识传播
2. 迅速锁定“涉疫”人员流动轨迹
3. 开展疫情发展态势预测与溯源
4. 助力地方政府科学精准施策
5. 推动病例诊断与疫情研究


## 什么是KDD？KDD的一般步骤是什么？
知识发现 (Knowledge Discovery in Database, KDD)，是所谓" 数据挖掘 "的一种更广义的说法，即从各种媒体表示的信息中，根据不同的需求获得知识。

1. 数据清理（消除噪声和不一致数据）
2. 数据集成（多种数据源组合在一起）
3. 数据选择（从数据库中提取与分析和任务相关的数据）
4. 数据变换（变换或同一成适合挖掘的形式）
5. 数据挖掘（用算法提取信息）
6. 模式评估（根据某种兴趣度度量，识别表示知识的真正有趣模式）
7. 知识表示（用可视化技术向用户展示）


## 什么是数据挖掘？KDD和数据挖掘有什么异同？
数据挖掘：从大量的数据中通过算法搜索隐藏于其中信息的过程

数据挖掘是数据库中知识发现 (knowledge discovery in database, KDD)不可缺少的一部分，而KDD是将未加工的数据转换为有用信息的整个过程，该过程包括一系列转换步骤， 从数据的预处理到数据挖掘结果的后处理。


## 简述下列数据挖掘技术的主要任务：分类、回归、聚类、关联规则挖掘。并举例说明每种技术的应用领域。

### classification (分类)。
分类是找出数据库中的一组数据对象的共同特点并按照分类模式将其划分为不同的类，其目的是通过分类模型，将数据库中的数据项映射到摸个给定的类别中。可以应用到应用分类、趋势预测中，如淘宝商铺将用户在一段时间内的购买情况划分成不同的类，根据情况向用户推荐关联类的商品，从而增加商铺的销售量。

### regression (回归)。
回归分析反映了数据库中数据的属性值的特性，通过函数表达数据映射的关系来发现属性值之间的依赖关系。它可以应用到对数据序列的预测及相关关系的研究中去。在市场营销中，回归分析可以被应用到各个方面。如通过对本季度销售的回归分析，对下一季度的销售趋势作出预测并做出针对性的营销改变。

### clustering (聚类)。
聚类类似于分类，但与分类的目的不同，是针对数据的相似性和差异性将一组数据分为几个类别。属于同一类别的数据间的相似性很大，但不同类别之间数据的相似性很小，跨类的数据关联性很低。

### association rule (关联规则)。
关联规则就是支持度与置信度分别满足用户给定阈值的规则。所谓关联，反映一个事件与其他事件间关联的知识。支持度揭示了A和B同时出现的频率。置信度揭示了B出现时，A有多大的可能出现。关联规则的挖掘过程主要包括两个阶段：第一阶段为从海量原始数据中找出所有的高频项目组;第二阶段为从这些高频项目组产生关联规则。关联规则挖掘技术已经被广泛应用于金融行业企业中用以预测客户的需求，各银行在自己的ATM 机上通过捆绑客户可能感兴趣的信息供用户了解并获取相应信息来改善自身的营销。


## 请说明传统的数据挖掘中数据预处理的主要任务是什么？
1. 数据清理：填写空缺值，平滑噪声数据，识别，删除孤立点，解决不一致性
2. 数据集成：集成多个数据库，数据立方体，文件


## Web数据挖掘可以分为几种主要类型，分别说明每种类型的具体任务。

### 1、Web结构挖掘
Web结构挖掘从表征Web构造的超级链接中找寻有价值的知识。比如：从这种连接中，能够找到什么是重要的网页页面，它是一项百度搜索引擎选用的重要技术应用。还可以挖掘具备相同兴趣爱好的客户小区。这种任務在传统式的大数据挖掘中并不会有，由于在关联型报表中并沒有连接构造。

### 2、Web內容挖掘
Web內容挖掘从网页页面中提取有价值的信息内容和知识。比如：依据网页页面的主题风格，能够进行全自动的聚类算法和归类。尽管这种任務与传统式大数据挖掘的任務类似，可是仍然能够为了更好地各种各样不一样的目地从网页页面中依据方式提取有价值的信息内容，比如产品描述、社区论坛回贴等。而这种信息内容能够被作为进一步剖析来挖掘客户心态。这种任務也不是传统式的大数据挖掘任務。

### 3、Web应用挖掘
Web应用挖掘从纪录每名客户点一下状况的应用日志中挖掘客户的浏览方式。此项任務也应用了很多大数据挖掘的优化算法。在其中一项重要的议案是点一下流数据的预备处理，便于形成能够用于挖掘的适合数据信息。


## 本课程主要内容可分为几部分，分别是什么。
第2章 关联规则和序列模式
2.1 关联规则的基本概念
2.2 Apriori算法
2.2.1 频繁项目集生成
2.2.2 关联规则生成
2.3 关联规则挖掘的数据格式
2.4 多小支持度的关联规则挖掘
2.4.1 扩展模型
2.4.2 挖掘算法
2.4.3 规则生成
2.5 分类关联规则挖掘
2.5.1 问题描述
2.5.2 挖掘算法
2.5.3 多小支持度分类关联规则挖掘
2.6 序列模式的基本概念
2.7 基于GSP挖掘序列模式
2.7.1 GSP算法
2.7.2 多小支持度挖掘
2.8 基于PrefixSpan算法的序列模式挖掘
2.8.1 PrefixSpan算法
2.8.2 多小支持度挖掘
2.9 从序列模式中产生规则
2.9.1 序列规则
2.9.2 标签序列规则
2.9.3 分类序列规则


第3章 监督学习
3.1 基本概念
3.2 决策树归纳
3.2.1 学习算法
3.2.2 混杂度函数
3.2.3 处理连续属性
3.2.4 其他一些问题
3.3 评估分类器
3.3.1 评估方法
3.3.2 查准率、查全率、F-score和平衡点（BreakevePoint）
3.3.3 受试者工作特征曲线
3.3.4 提升曲线
3.4 规则归纳
3.4.1 顺序化覆盖
3.4.2 规则学习：Learn-One-Rule函数
3.4.3 讨论
3.5 基于关联规则的分类
3.5.1 使用类关联规则进行分类
3.5.2 使用类关联规则作为分类属性
3.5.3 使用古典的关联规则分类
3.6 朴素贝叶斯分类
3.7 朴素贝叶斯文本分类
3.7.1 概率框架
3.7.2 朴素贝叶斯模型
3.7.3 讨论
3.8 支持向量机
3.8.1 线性支持向量机：可分的情况
3.8.2 线性支持向量机：数据不可分的情况
3.8.3 非线性支持向量机：核方法总结
3.9 A、近邻学习
3.10 分类器的集成
3.10.1 Bagging
3.10.2 Boosting


第4章 无监督学习
4.1 基本概念
4.2 A-均值聚类
4.2.1 A-均值算法
4.2.2 A-均值算法的硬盘版本
4.2.3 优势和劣势
4.3 聚类的表示
4.3.1 聚类的一般表示方法
4.3.2 任意形状的聚类
4.4 层次聚类
4.4.1 单连结方法
4.4.2 全连结方法
4.4.3 平均连结方法
4.4.4 优势和劣势
4.5 距离函数
4.5.1 数字属性
4.5.2 布尔属性和名词性属性
4.5.3 文本文档
4.6 数据标准化
4.7 混合属性的处理
4.8 采用哪种聚类算法
4.9 聚类的评估
4.10 发现数据区域和数据空洞


第5章 部分监督学习
5.1 从已标注数据和无标注数据中学习
5.1.1 使用朴素贝叶斯分类器的EM算法
5.1.2 Co-naining
5.1.3 自学习
5.1.4 直推式支持向量机
5.1.5 基于图的方法
5.1.6 讨论
5.2 从正例和无标注数据中学习
5.2.1 PU学习的应用
5.2.2 理论基础
5.2.3 建立分类器：两步方法
5.2.4 建立分类器：偏置SVM
5.2.5 建立分类器：概率估计
5.2.6 讨论

...


## 简述什么是有监督学习和无监督学习。
监督学习是指数据集的正确输出已知情况下的一类学习算法。因为输入和输出已知，意味着输入和输出之间有一个关系，监督学习算法就是要发现和总结这种“关系”。

无监督学习是指对无标签数据的一类学习算法。因为没有标签信息，意味着需要从数据集中发现和总结模式或者结构。
我们基于数据中的变量之间关系利用聚类算法发现这种内在模式或者结构。


## 课外阅读：Chapter 1, Chapter 2 and Chapter 3


- [WEB发展简史，Web1.0到Web3.0的发展历程](https://blog.csdn.net/Hu1510592894/article/details/89015682)
- [疫情防控中的大数据与智能应用分析](https://zhuanlan.zhihu.com/p/118060390)
- [KDD数据库知识发现流程](https://blog.csdn.net/alanlonglong/article/details/79055008)
- [简述聚类、分类、回归、关联分析的不同，需要分析常见算法并用现实应用场景说明](https://blog.csdn.net/longmei101/article/details/108204790)
- [web挖掘都有哪些类型](https://www.qy.cn/zx/spread/9003.html)
- [有监督学习与无监督学习](https://blog.csdn.net/u010420283/article/details/83758378)

